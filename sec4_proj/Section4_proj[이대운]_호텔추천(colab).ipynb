{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Section4_proj[이대운]_호텔추천(colab).ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZsA8Jg1lwGY"
      },
      "source": [
        "# 📄 sec4_project_recommend_hotel_in_spain\n",
        "- 호텔예약 및 리뷰 데이터로 해당데이터들을 통해 데이터를 통해 고객들이 원하는 조건의 호텔을 추천하는 모델을 제작했다.\n",
        "\n",
        "- 데이터에서 몇몇 칼럼을 뽑아 해당 특성을 통해 고객이 원하는 유형의 호텔의 가장많은 숙박객수를 보유한 호텔을 알려주고, 고객이 원하는 호텔의 조건(싫어하는조건, 좋아하는조건)을 자연어 처리를 통해 가장 비슷한 리뷰를 가진 호텔 5개씩을 알려주는 모델이다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZqSfcBnr03u"
      },
      "source": [
        "## 데이터 소개"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peakHLber6Gf"
      },
      "source": [
        "### 데이터 내용\n",
        "- 해당 데이터는 캐글의 [515K Hotel Reviews Data in Europe](https://www.kaggle.com/jiashenliu/515k-hotel-reviews-data-in-europe)\n",
        "에서 받아왔습니다.\n",
        "\n",
        "- 위 페이지에서 소개하기로는 Booking.com에서 스크랩 되었다고 하며, 유럽의 1493개의 럭셔리호텔들에 대한 515,000개의 리뷰를 데이터로 가지고 있습니다.\n",
        "\n",
        "- 515,000개의 데이터 중 \n",
        "Spain의 Barcelona에 있는 호텔들의 2016~2017년 데이터로만 프로젝트를 진행함"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsQu40zpQ5DM"
      },
      "source": [
        "### 데이터 선정이유\n",
        "\n",
        "- 해당 데이터를 통해 고객들이 원하는 호텔은 추천하고자 한다.\n",
        "  - 사용자는 호텔의 유형 즉 여행목적, 룸컨디션 등을 선택하고 자신이 찾고자 하는 호텔 혹은 가고싶지 않은 호텔의 조건을 추가적으로 기입하여 이전 리뷰에 해당 조건이 존재한다면, 제외하거나 추천하여 사용자들이 필요로 하는 호텔을 적극적으로 추천한다.\n",
        "\n",
        "- \"어떤 회사에서 높이 살 수 있을까?\"\n",
        "   - 해당 데이터가 '호텔'에 국한되어 있지만, 고객에게 제품을 판매하거나, 고객의 요구를 파악하여 추천하는 서비스를 제공하고자 하는 회사라면 비슷한 데이터를 가지고 있을경우 사용될 수 있을 것이라 생각한다. \n",
        "\n",
        "- \"어디 회사의 어느부분에 적용해 볼 수 있을까\"\n",
        "  - \"호텔예약서비스를 제공하는 회사의 호텔추천 서비스, 유통판매업의 같은 상품류 별 추천상품을 제공하는 서비스 등\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2PVYpFdxMDf"
      },
      "source": [
        "### 테이터를 이용한 가설\n",
        "- 호텔을 이용한 고객들의 리뷰를 분석하여 호텔추천 서비스를 이용하려는 고객들의 니즈에 맞춰서 호텔을 추천하여 고객의 편리성을 높힐 수 있을 것다\n",
        "- 리뷰들을 자연어처리를 통해 분석하여 k-nn모델을 통해 가장 근접한 문서를 찾고 해당 문서에 해당하는 호텔의 이름을 뽑아 출력할 수 있을것이다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__TDLTuGs_jg"
      },
      "source": [
        "### 칼럼\n",
        "- Hotel_Address: 호텔주소\n",
        "- Review_Date: 리뷰한 날짜\n",
        "- Average_Score: 호텔의 평균 점수(지난해 최신 코멘트를 기반으로 계산됨)\n",
        "- Hotel_Name: 호텔이름\n",
        "- Reviewer_Nationality: 리뷰어의 국적\n",
        "- Negative_Review: 부정적 리뷰. 없을 경우 'No Negative'로 표기\n",
        "- ReviewTotalNegativeWordCounts: 부정적 리뷰에 사용된 총 단어의 수\n",
        "- Positive_Review: 긍정적 리뷰. 없을 경우 'No Positive'로 표기\n",
        "- ReviewTotalPositiveWordCounts: 긍정적 리뷰에 사용된 총 단어의 수\n",
        "- Reviewer_Score: 리뷰 점수\n",
        "- TotalNumberofReviewsReviewerHasGiven: 리뷰어의 지난 리뷰들의 갯수\n",
        "- TotalNumberof_Reviews: 호텔이 가진 리뷰의 수\n",
        "- Tags: 리뷰어가 호텔에 단 태그\n",
        "- dayssincereview: 검토 날짜와 스크래핑 날짜 사이의 기간입니다.\n",
        "- AdditionalNumberof_Scoring: 투숙객들에 의한 호텔의 평가점수(리뷰를 작성하지 않은 평가자도 존재)\n",
        "- lat: 호텔의 위도\n",
        "- lng: 호텔의 경도\n",
        "\n",
        "------------------------------\n",
        "### 사용할 칼럼\n",
        "Hotel_Address, Hotel_Name, Negative_Review, Positive_Review, Tags"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvRBvbfHqefc"
      },
      "source": [
        "# kaggle api\n",
        "!pip install kaggle\n",
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EADddFsJqqBz"
      },
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "# Permission Warning이 발생하지 않도록 해줍니다.\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvTjUYLTrSXg"
      },
      "source": [
        "! kaggle datasets download -d jiashenliu/515k-hotel-reviews-data-in-europe"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMielVlRrWk1"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SO3kd_aGrYBL"
      },
      "source": [
        "!unzip 515k-hotel-reviews-data-in-europe.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CAD4qmCvKfDE"
      },
      "source": [
        "## 데이터 분석"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZAJurOSaCDY"
      },
      "source": [
        "!pip install squarify"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvbkmJvYKksz"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import spacy\n",
        "import re\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99JPff5rK5jb"
      },
      "source": [
        "# 데이터 읽어와서 스페인의 16-17년 정보만 남기기\n",
        "data1 = pd.read_csv('Hotel_Reviews.csv')\n",
        "data2017_16 = data1[data1['Review_Date'].str.split('/').str[2] >= '2016']\n",
        "spain2016_17 = data1[data1['Hotel_Address'].str.split().str[-1] == 'Spain']\n",
        "df = spain2016_17[['Hotel_Address', 'Hotel_Name', 'Negative_Review', 'Positive_Review', 'Tags']].reset_index(drop=True)\n",
        "print(f\"df_shape:{df.shape}\")\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEcvcLifXEU1"
      },
      "source": [
        "### 전처리\n",
        "- 'Tags' 피처에서 숙박목적, 인원, 방규모 분리하기\n",
        "    - 인원, 방규모는 데이터가 너무 지저분 하여 제외함\n",
        "  - 특성의 전처리: 소문자화, 알파벳과 숫자 ' , '빼고 삭제\n",
        "  - ' , '기준으로 구분짓고 새로운 특성으로 생성 후 기존 'Tags'삭제\n",
        "- 리뷰들의 토큰화\n",
        "  - 소문자화 및 불용어처리\n",
        "  - 표제어추출"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MxGoZeGlUoA"
      },
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "STOP_WORDS_union = nlp.Defaults.stop_words.union(['negative', 't', 'hotel', 'didn', ' '])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_s8I4hTlLBRI"
      },
      "source": [
        " # # 국가-도시 분리 - 스페인만 할때는 불필요함\n",
        "# def split_country_city(data):\n",
        "#   try:\n",
        "#     data['City'] = data['Hotel_Name'].str.split(' ').str[-2]\n",
        "#     data['Country'] = data['Hotel_Address'].str.split(' ').str[-1]\n",
        "#     data = data.drop('Hotel_Address', axis=1)\n",
        "#     data = data[['Country', 'City', 'Hotel_Name', 'Negative_Review', 'Positive_Review', 'Tags']]\n",
        "#     print(\"split_city_country: Done!\")\n",
        "#   except:\n",
        "#     print(\"split_city_country: already Done Or Not found [Hotel_Address]\")\n",
        "#   return data\n",
        "\n",
        "# 같은 호텔리뷰 합쳐서 호텔들의 리뷰 리스트로 만들기\n",
        "def split_hotel_review(data, review_category):\n",
        "  try:\n",
        "    reviews = []\n",
        "    hotel_list = data['Hotel_Name'].unique()\n",
        "    for i in hotel_list:\n",
        "      review = ''\n",
        "      hotel1 = data[data['Hotel_Name'] == i]\n",
        "      for i in hotel1[review_category]:\n",
        "        review = review +'. '+ i\n",
        "      reviews.append(review)\n",
        "    print(\"split_hotel_review: Done\")\n",
        "  except:\n",
        "    print(\"split_hotel_review: already Done Or Not found [Hotel_Name]\")\n",
        "  return reviews\n",
        "\n",
        "# ['Tags'] 전처리용 \n",
        "def tags_preprocessing(data):\n",
        "  for idx, text in enumerate(data):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"[^a-z0-9,]\", '', text)\n",
        "    text = text.replace('\\n', ' ')\n",
        "    data[idx] = text\n",
        "  print('tags_preprocessing: Done!')\n",
        "  return data\n",
        "\n",
        "# 리뷰 토큰화\n",
        "def get_lemmas(data):\n",
        "  tokenizer = spacy.tokenizer.Tokenizer(nlp.vocab)\n",
        "  tokens = []\n",
        "  for doc in tokenizer.pipe(data):\n",
        "    lemmas = []\n",
        "    for token in doc: \n",
        "      if token.text.lower() not in STOP_WORDS_union:\n",
        "        if ((token.is_stop == False) and (token.is_punct == False)) and (token.pos_ != 'PRON'):\n",
        "          lemmas.append(token.lemma_.lower())\n",
        "    tokens.append(lemmas)\n",
        "  print(\"get_lemmas: Done!\")\n",
        "  return tokens\n",
        "\n",
        "# 태그 분류하기\n",
        "def split_Tags(data):\n",
        "  count = 0\n",
        "  try:\n",
        "    data['travel_perpos'] = data['Tags'].str.split(',').str[0]\n",
        "    # data['traveler_category'] = data['Tags'].str.split(',').str[1]\n",
        "    # data['room_condition'] = data['Tags'].str.split(',').str[2]\n",
        "    data = data.drop('Tags', axis=1)\n",
        "    print(\"split_Tags: Done, Without Submitted_from_mobiledevice!\")\n",
        "  except:\n",
        "    print(\"split_Tags: already Done Or Not found [Tags]\")\n",
        "  return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTG3KWDvfoDn"
      },
      "source": [
        "# df = split_city_country(df)\n",
        "df['Tags'] = tags_preprocessing(df['Tags'])\n",
        "df = split_Tags(df)\n",
        "\n",
        "Negative_Review = split_hotel_review(df, 'Negative_Review')\n",
        "Positive_Review = split_hotel_review(df, 'Positive_Review')\n",
        "\n",
        "df['Negative_Review'] = get_lemmas(df['Negative_Review'])\n",
        "df['Positive_Review'] = get_lemmas(df['Positive_Review'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9UTGBeMj-z6"
      },
      "source": [
        "from collections import Counter\n",
        "def word_count(docs):\n",
        "    \"\"\" 토큰화된 문서들을 입력받아 토큰을 카운트 하고 관련된 속성을 가진 데이터프레임을 리턴합니다.\n",
        "    Args:\n",
        "        docs (series or list): 토큰화된 문서가 들어있는 list\n",
        "    Returns:\n",
        "        list: Dataframe\n",
        "    \"\"\"\n",
        "    # 전체 코퍼스에서 단어 빈도 카운트\n",
        "    word_counts = Counter()\n",
        "\n",
        "    # 단어가 존재하는 문서의 빈도 카운트, 단어가 한 번 이상 존재하면 +1\n",
        "    word_in_docs = Counter()\n",
        "\n",
        "    # 전체 문서의 갯수\n",
        "    total_docs = len(docs)\n",
        "\n",
        "    for doc in docs:\n",
        "        word_counts.update(doc)\n",
        "        word_in_docs.update(set(doc))\n",
        "\n",
        "    temp = zip(word_counts.keys(), word_counts.values())\n",
        "\n",
        "    wc = pd.DataFrame(temp, columns = ['word', 'count'])\n",
        "\n",
        "    # 단어의 순위\n",
        "    # method='first': 같은 값의 경우 먼저나온 요소를 우선\n",
        "    wc['rank'] = wc['count'].rank(method='first', ascending=False)\n",
        "    total = wc['count'].sum()\n",
        "\n",
        "    # 코퍼스 내 단어의 비율\n",
        "    wc['percent'] = wc['count'].apply(lambda x: x / total)\n",
        "\n",
        "    wc = wc.sort_values(by='rank')\n",
        "\n",
        "    # 누적 비율\n",
        "    # cumsum() : cumulative sum\n",
        "    wc['cul_percent'] = wc['percent'].cumsum()\n",
        "\n",
        "    temp2 = zip(word_in_docs.keys(), word_in_docs.values())\n",
        "    ac = pd.DataFrame(temp2, columns=['word', 'word_in_docs'])\n",
        "    wc = ac.merge(wc, on='word')\n",
        "    \n",
        "    # 전체 문서 중 존재하는 비율\n",
        "    wc['word_in_docs_percent'] = wc['word_in_docs'].apply(lambda x: x / total_docs)\n",
        "\n",
        "    return wc.sort_values(by='rank')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rkxn3dxzayh"
      },
      "source": [
        "import squarify\n",
        "Negative_Review_wc = word_count(df['Negative_Review'])\n",
        "Negative_Review_wc_top10 = Negative_Review_wc[Negative_Review_wc['rank'] <= 10]\n",
        "print(\"Negative_Review_word_top10\")\n",
        "squarify.plot(sizes=Negative_Review_wc_top10['percent'], label=Negative_Review_wc_top10['word'], alpha=0.6 )\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "Negative_Review_wc_top10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCvMOON9lXQq"
      },
      "source": [
        "Positive_Review_wc = word_count(df['Positive_Review'])\n",
        "Positive_Review_wc_top10 = Positive_Review_wc[Positive_Review_wc['rank'] <= 10]\n",
        "print(\"Positive_Review_word_top10\")\n",
        "squarify.plot(sizes=Positive_Review_wc_top10['percent'], label=Positive_Review_wc_top10['word'], alpha=0.6 )\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "Positive_Review_wc_top10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PL0zSH_utxuQ"
      },
      "source": [
        "### 리뷰 벡터화(TF-IDF)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "if9iYATiuXa_"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1Tc0q2M2vnm"
      },
      "source": [
        "# plot 스타일과 폰트 크기를 설정합니다.\n",
        "sns.set(style='whitegrid', font_scale=1.15)\n",
        "\n",
        "# 문서별 단어의 수 분포도 그리는 함수\n",
        "def plot_text_length_dist(text_list):\n",
        "\n",
        "    # 문장이 요소인 리스트를 받아 각 문서의 단어 수를 가진 리스트를 만듭니다\n",
        "    num_words = [len(doc.split()) for doc in text_list]\n",
        "    \n",
        "    sns.displot(num_words)\n",
        "    plt.title('# of words per documents')\n",
        "    plt.xlabel('Number of words')\n",
        "    plt.ylabel('Number of documents')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58PrBKnRiwhy"
      },
      "source": [
        "plot_text_length_dist(Positive_Review)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2U0zWGrA2xJi"
      },
      "source": [
        "plot_text_length_dist(Negative_Review)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09Vjb7KF38H_"
      },
      "source": [
        "# spacy tokenizer 함수\n",
        "def tokenize(document):\n",
        "    \n",
        "    doc = nlp(document)\n",
        "    # punctuations: !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
        "    return [token.lemma_.strip() for token in doc if (token.is_stop != True) and (token.is_punct != True) and (token.is_alpha == True)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvWQPtqGlzDc"
      },
      "source": [
        "# Tf-IDF\n",
        "N_tfidf = TfidfVectorizer(stop_words='english'\n",
        "                        ,tokenizer=tokenize\n",
        "                        ,ngram_range=(1,2)\n",
        "                        ,max_df=.7\n",
        "                        ,min_df=3\n",
        "                        ,max_features = 20000\n",
        "                       )\n",
        "P_tfidf = TfidfVectorizer(stop_words='english'\n",
        "                        ,tokenizer=tokenize\n",
        "                        ,ngram_range=(1,2)\n",
        "                        ,max_df=.7\n",
        "                        ,min_df=3\n",
        "                        ,max_features = 20000\n",
        "                       )\n",
        "Negative_Review_dtm = N_tfidf.fit_transform(Negative_Review)\n",
        "Negative_Review_dtm = pd.DataFrame(Negative_Review_dtm.todense(), columns=N_tfidf.get_feature_names())\n",
        "print(Negative_Review_dtm.head())\n",
        "\n",
        "Positive_Review_dtm = P_tfidf.fit_transform(Positive_Review)\n",
        "Positive_Review_dtm = pd.DataFrame(Positive_Review_dtm.todense(), columns=P_tfidf.get_feature_names())\n",
        "print(Positive_Review_dtm.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPHBbsf2kHNa"
      },
      "source": [
        "### 유사도를 이용한 문서검색(NearestNeighbor (K-NN, K-최근접 이웃))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOBsEfsH3-In"
      },
      "source": [
        "# NearestNeighbor (K-NN, K-최근접 이웃)\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# dtm을 사용히 NN 모델을 학습시킵니다. (디폴트)최근접 5 이웃.\n",
        "Negative_Review_nn = NearestNeighbors(n_neighbors=5, algorithm='kd_tree')\n",
        "Negative_Review_nn.fit(Negative_Review_dtm)\n",
        "\n",
        "Positive_Review_nn = NearestNeighbors(n_neighbors=5, algorithm='kd_tree')\n",
        "Positive_Review_nn.fit(Positive_Review_dtm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTGsJh0N4hdK"
      },
      "source": [
        "Negative_Review_nn.kneighbors([Negative_Review_dtm.iloc[0].values])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBbGGb__joKG"
      },
      "source": [
        "Positive_Review_nn.kneighbors([Positive_Review_dtm.iloc[0].values])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmS62jV_BZRy"
      },
      "source": [
        "기능추가"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GIa8qHy_2UZ"
      },
      "source": [
        "# ['travel_perpos']을 통해서 해당 유형에서 가장 많이 예약된 상위 5개의 호텔 알려주기\n",
        "def top5_hotel_by_travel_perpos(data, travel_perpos):\n",
        "  travel_perpos_ls = data['travel_perpos'].unique()\n",
        "  hotel_list = data['Hotel_Name'].unique()\n",
        "  dic = {}\n",
        "  for i in hotel_list:\n",
        "    s = data[data['Hotel_Name']==i]['travel_perpos']=='travel_perpos'\n",
        "    dic[i]=s.count()\n",
        "  top5 = sorted(dic.items(), key=lambda x: x[1], reverse=True)[0:5]\n",
        "  print(f\"입력된 숙박목적은 '{travel_perpos}'이며, 해당 목적으로 가장많이 이용된 상위5개 호텔과 이용자 수 는 다음과 같습니다. \")\n",
        "  return top5\n",
        "\n",
        "# 사용자의 추가적인 조건에 따라 호텔 추천하기\n",
        "def kneighbors(data, Negative, Positive):\n",
        "  hotel_list = data['Hotel_Name'].unique()\n",
        "  test_N = N_tfidf.transform(Negative)\n",
        "  test_P = P_tfidf.transform(Positive)\n",
        "  Negative_kneighbors=Negative_Review_nn.kneighbors(test_N.todense())[1][0]\n",
        "  Positive_kneighbors=Positive_Review_nn.kneighbors(test_P.todense())[1][0]\n",
        "  print(f\"입력된 싫어하는 호텔조건은\\n {Negative}\\n이며, 입력된 조건과 비슷한 리뷰가 있는 호텔은 다음과 같습니다.\")\n",
        "  for i in hotel_list[Negative_kneighbors]:\n",
        "    print(i)\n",
        "  print(\"\\n\")\n",
        "  print(f\"입력된 선호하는 호텔조건은\\n {Positive}\\n이며, 입력된 조건과 비슷한 리뷰가 있는 호텔은 다음과 같습니다.\")\n",
        "  for i in hotel_list[Positive_kneighbors]:\n",
        "    print(i)\n",
        "  return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjItE40PlFGt"
      },
      "source": [
        "## 결과 알려주기\n",
        "- ['travel_perpos']을 통해서 해당 유형에서 숙박리뷰가 가장 많은 호텔 알려주기\n",
        "- 싫어하는 호텔조건을 통해 비슷한 네거티브리뷰가 있는 호텔 알려주\n",
        "- 좋아하는 호텔조건을 통해 비슷한 포지티브리뷰가 있는 호텔 알려주기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_WkDznxpWtg"
      },
      "source": [
        "# ['travel_perpos']의 종류\n",
        "travel_perpos = ['leisuretrip', 'businesstrip', 'couple', 'solotraveler',\n",
        "       'familywithyoungchildren', 'withapet', 'group',\n",
        "       'travelerswithfriends', 'familywitholderchildren']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tr8gFKr9E4wt"
      },
      "source": [
        "# bug, nosie, unkind staff\n",
        "# nice step, good breakfast, pool"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmvhHs17DV7K"
      },
      "source": [
        "user1 = {\n",
        "    'travel_perpos':input(\"travel_perpos?:\"),\n",
        "    'n1':[input(\"negative_r?: \")],\n",
        "    'p1':[input(\"positive_r?: \")]\n",
        "    }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1ql-mEpAx-w"
      },
      "source": [
        "top5_hotel_by_travel_perpos(df, user1['travel_perpos'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Suy7HQBRFi71"
      },
      "source": [
        "kneighbors(df, user1['n1'], user1['p1'])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}