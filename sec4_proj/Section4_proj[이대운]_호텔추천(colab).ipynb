{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Section4_proj[ì´ëŒ€ìš´]_í˜¸í…”ì¶”ì²œ(colab).ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZsA8Jg1lwGY"
      },
      "source": [
        "# ğŸ“„ sec4_project_recommend_hotel_in_spain\n",
        "- í˜¸í…”ì˜ˆì•½ ë° ë¦¬ë·° ë°ì´í„°ë¡œ í•´ë‹¹ë°ì´í„°ë“¤ì„ í†µí•´ ë°ì´í„°ë¥¼ í†µí•´ ê³ ê°ë“¤ì´ ì›í•˜ëŠ” ì¡°ê±´ì˜ í˜¸í…”ì„ ì¶”ì²œí•˜ëŠ” ëª¨ë¸ì„ ì œì‘í–ˆë‹¤.\n",
        "\n",
        "- ë°ì´í„°ì—ì„œ ëª‡ëª‡ ì¹¼ëŸ¼ì„ ë½‘ì•„ í•´ë‹¹ íŠ¹ì„±ì„ í†µí•´ ê³ ê°ì´ ì›í•˜ëŠ” ìœ í˜•ì˜ í˜¸í…”ì˜ ê°€ì¥ë§ì€ ìˆ™ë°•ê°ìˆ˜ë¥¼ ë³´ìœ í•œ í˜¸í…”ì„ ì•Œë ¤ì£¼ê³ , ê³ ê°ì´ ì›í•˜ëŠ” í˜¸í…”ì˜ ì¡°ê±´(ì‹«ì–´í•˜ëŠ”ì¡°ê±´, ì¢‹ì•„í•˜ëŠ”ì¡°ê±´)ì„ ìì—°ì–´ ì²˜ë¦¬ë¥¼ í†µí•´ ê°€ì¥ ë¹„ìŠ·í•œ ë¦¬ë·°ë¥¼ ê°€ì§„ í˜¸í…” 5ê°œì”©ì„ ì•Œë ¤ì£¼ëŠ” ëª¨ë¸ì´ë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZqSfcBnr03u"
      },
      "source": [
        "## ë°ì´í„° ì†Œê°œ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peakHLber6Gf"
      },
      "source": [
        "### ë°ì´í„° ë‚´ìš©\n",
        "- í•´ë‹¹ ë°ì´í„°ëŠ” ìºê¸€ì˜ [515K Hotel Reviews Data in Europe](https://www.kaggle.com/jiashenliu/515k-hotel-reviews-data-in-europe)\n",
        "ì—ì„œ ë°›ì•„ì™”ìŠµë‹ˆë‹¤.\n",
        "\n",
        "- ìœ„ í˜ì´ì§€ì—ì„œ ì†Œê°œí•˜ê¸°ë¡œëŠ” Booking.comì—ì„œ ìŠ¤í¬ë© ë˜ì—ˆë‹¤ê³  í•˜ë©°, ìœ ëŸ½ì˜ 1493ê°œì˜ ëŸ­ì…”ë¦¬í˜¸í…”ë“¤ì— ëŒ€í•œ 515,000ê°œì˜ ë¦¬ë·°ë¥¼ ë°ì´í„°ë¡œ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "- 515,000ê°œì˜ ë°ì´í„° ì¤‘ \n",
        "Spainì˜ Barcelonaì— ìˆëŠ” í˜¸í…”ë“¤ì˜ 2016~2017ë…„ ë°ì´í„°ë¡œë§Œ í”„ë¡œì íŠ¸ë¥¼ ì§„í–‰í•¨"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsQu40zpQ5DM"
      },
      "source": [
        "### ë°ì´í„° ì„ ì •ì´ìœ \n",
        "\n",
        "- í•´ë‹¹ ë°ì´í„°ë¥¼ í†µí•´ ê³ ê°ë“¤ì´ ì›í•˜ëŠ” í˜¸í…”ì€ ì¶”ì²œí•˜ê³ ì í•œë‹¤.\n",
        "  - ì‚¬ìš©ìëŠ” í˜¸í…”ì˜ ìœ í˜• ì¦‰ ì—¬í–‰ëª©ì , ë£¸ì»¨ë””ì…˜ ë“±ì„ ì„ íƒí•˜ê³  ìì‹ ì´ ì°¾ê³ ì í•˜ëŠ” í˜¸í…” í˜¹ì€ ê°€ê³ ì‹¶ì§€ ì•Šì€ í˜¸í…”ì˜ ì¡°ê±´ì„ ì¶”ê°€ì ìœ¼ë¡œ ê¸°ì…í•˜ì—¬ ì´ì „ ë¦¬ë·°ì— í•´ë‹¹ ì¡°ê±´ì´ ì¡´ì¬í•œë‹¤ë©´, ì œì™¸í•˜ê±°ë‚˜ ì¶”ì²œí•˜ì—¬ ì‚¬ìš©ìë“¤ì´ í•„ìš”ë¡œ í•˜ëŠ” í˜¸í…”ì„ ì ê·¹ì ìœ¼ë¡œ ì¶”ì²œí•œë‹¤.\n",
        "\n",
        "- \"ì–´ë–¤ íšŒì‚¬ì—ì„œ ë†’ì´ ì‚´ ìˆ˜ ìˆì„ê¹Œ?\"\n",
        "   - í•´ë‹¹ ë°ì´í„°ê°€ 'í˜¸í…”'ì— êµ­í•œë˜ì–´ ìˆì§€ë§Œ, ê³ ê°ì—ê²Œ ì œí’ˆì„ íŒë§¤í•˜ê±°ë‚˜, ê³ ê°ì˜ ìš”êµ¬ë¥¼ íŒŒì•…í•˜ì—¬ ì¶”ì²œí•˜ëŠ” ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•˜ê³ ì í•˜ëŠ” íšŒì‚¬ë¼ë©´ ë¹„ìŠ·í•œ ë°ì´í„°ë¥¼ ê°€ì§€ê³  ìˆì„ê²½ìš° ì‚¬ìš©ë  ìˆ˜ ìˆì„ ê²ƒì´ë¼ ìƒê°í•œë‹¤. \n",
        "\n",
        "- \"ì–´ë”” íšŒì‚¬ì˜ ì–´ëŠë¶€ë¶„ì— ì ìš©í•´ ë³¼ ìˆ˜ ìˆì„ê¹Œ\"\n",
        "  - \"í˜¸í…”ì˜ˆì•½ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•˜ëŠ” íšŒì‚¬ì˜ í˜¸í…”ì¶”ì²œ ì„œë¹„ìŠ¤, ìœ í†µíŒë§¤ì—…ì˜ ê°™ì€ ìƒí’ˆë¥˜ ë³„ ì¶”ì²œìƒí’ˆì„ ì œê³µí•˜ëŠ” ì„œë¹„ìŠ¤ ë“±\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2PVYpFdxMDf"
      },
      "source": [
        "### í…Œì´í„°ë¥¼ ì´ìš©í•œ ê°€ì„¤\n",
        "- í˜¸í…”ì„ ì´ìš©í•œ ê³ ê°ë“¤ì˜ ë¦¬ë·°ë¥¼ ë¶„ì„í•˜ì—¬ í˜¸í…”ì¶”ì²œ ì„œë¹„ìŠ¤ë¥¼ ì´ìš©í•˜ë ¤ëŠ” ê³ ê°ë“¤ì˜ ë‹ˆì¦ˆì— ë§ì¶°ì„œ í˜¸í…”ì„ ì¶”ì²œí•˜ì—¬ ê³ ê°ì˜ í¸ë¦¬ì„±ì„ ë†’í ìˆ˜ ìˆì„ ê²ƒë‹¤\n",
        "- ë¦¬ë·°ë“¤ì„ ìì—°ì–´ì²˜ë¦¬ë¥¼ í†µí•´ ë¶„ì„í•˜ì—¬ k-nnëª¨ë¸ì„ í†µí•´ ê°€ì¥ ê·¼ì ‘í•œ ë¬¸ì„œë¥¼ ì°¾ê³  í•´ë‹¹ ë¬¸ì„œì— í•´ë‹¹í•˜ëŠ” í˜¸í…”ì˜ ì´ë¦„ì„ ë½‘ì•„ ì¶œë ¥í•  ìˆ˜ ìˆì„ê²ƒì´ë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__TDLTuGs_jg"
      },
      "source": [
        "### ì¹¼ëŸ¼\n",
        "- Hotel_Address: í˜¸í…”ì£¼ì†Œ\n",
        "- Review_Date: ë¦¬ë·°í•œ ë‚ ì§œ\n",
        "- Average_Score: í˜¸í…”ì˜ í‰ê·  ì ìˆ˜(ì§€ë‚œí•´ ìµœì‹  ì½”ë©˜íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê³„ì‚°ë¨)\n",
        "- Hotel_Name: í˜¸í…”ì´ë¦„\n",
        "- Reviewer_Nationality: ë¦¬ë·°ì–´ì˜ êµ­ì \n",
        "- Negative_Review: ë¶€ì •ì  ë¦¬ë·°. ì—†ì„ ê²½ìš° 'No Negative'ë¡œ í‘œê¸°\n",
        "- ReviewTotalNegativeWordCounts: ë¶€ì •ì  ë¦¬ë·°ì— ì‚¬ìš©ëœ ì´ ë‹¨ì–´ì˜ ìˆ˜\n",
        "- Positive_Review: ê¸ì •ì  ë¦¬ë·°. ì—†ì„ ê²½ìš° 'No Positive'ë¡œ í‘œê¸°\n",
        "- ReviewTotalPositiveWordCounts: ê¸ì •ì  ë¦¬ë·°ì— ì‚¬ìš©ëœ ì´ ë‹¨ì–´ì˜ ìˆ˜\n",
        "- Reviewer_Score: ë¦¬ë·° ì ìˆ˜\n",
        "- TotalNumberofReviewsReviewerHasGiven: ë¦¬ë·°ì–´ì˜ ì§€ë‚œ ë¦¬ë·°ë“¤ì˜ ê°¯ìˆ˜\n",
        "- TotalNumberof_Reviews: í˜¸í…”ì´ ê°€ì§„ ë¦¬ë·°ì˜ ìˆ˜\n",
        "- Tags: ë¦¬ë·°ì–´ê°€ í˜¸í…”ì— ë‹¨ íƒœê·¸\n",
        "- dayssincereview: ê²€í†  ë‚ ì§œì™€ ìŠ¤í¬ë˜í•‘ ë‚ ì§œ ì‚¬ì´ì˜ ê¸°ê°„ì…ë‹ˆë‹¤.\n",
        "- AdditionalNumberof_Scoring: íˆ¬ìˆ™ê°ë“¤ì— ì˜í•œ í˜¸í…”ì˜ í‰ê°€ì ìˆ˜(ë¦¬ë·°ë¥¼ ì‘ì„±í•˜ì§€ ì•Šì€ í‰ê°€ìë„ ì¡´ì¬)\n",
        "- lat: í˜¸í…”ì˜ ìœ„ë„\n",
        "- lng: í˜¸í…”ì˜ ê²½ë„\n",
        "\n",
        "------------------------------\n",
        "### ì‚¬ìš©í•  ì¹¼ëŸ¼\n",
        "Hotel_Address, Hotel_Name, Negative_Review, Positive_Review, Tags"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvRBvbfHqefc"
      },
      "source": [
        "# kaggle api\n",
        "!pip install kaggle\n",
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EADddFsJqqBz"
      },
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "# Permission Warningì´ ë°œìƒí•˜ì§€ ì•Šë„ë¡ í•´ì¤ë‹ˆë‹¤.\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvTjUYLTrSXg"
      },
      "source": [
        "! kaggle datasets download -d jiashenliu/515k-hotel-reviews-data-in-europe"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMielVlRrWk1"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SO3kd_aGrYBL"
      },
      "source": [
        "!unzip 515k-hotel-reviews-data-in-europe.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CAD4qmCvKfDE"
      },
      "source": [
        "## ë°ì´í„° ë¶„ì„"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZAJurOSaCDY"
      },
      "source": [
        "!pip install squarify"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvbkmJvYKksz"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import spacy\n",
        "import re\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99JPff5rK5jb"
      },
      "source": [
        "# ë°ì´í„° ì½ì–´ì™€ì„œ ìŠ¤í˜ì¸ì˜ 16-17ë…„ ì •ë³´ë§Œ ë‚¨ê¸°ê¸°\n",
        "data1 = pd.read_csv('Hotel_Reviews.csv')\n",
        "data2017_16 = data1[data1['Review_Date'].str.split('/').str[2] >= '2016']\n",
        "spain2016_17 = data1[data1['Hotel_Address'].str.split().str[-1] == 'Spain']\n",
        "df = spain2016_17[['Hotel_Address', 'Hotel_Name', 'Negative_Review', 'Positive_Review', 'Tags']].reset_index(drop=True)\n",
        "print(f\"df_shape:{df.shape}\")\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEcvcLifXEU1"
      },
      "source": [
        "### ì „ì²˜ë¦¬\n",
        "- 'Tags' í”¼ì²˜ì—ì„œ ìˆ™ë°•ëª©ì , ì¸ì›, ë°©ê·œëª¨ ë¶„ë¦¬í•˜ê¸°\n",
        "    - ì¸ì›, ë°©ê·œëª¨ëŠ” ë°ì´í„°ê°€ ë„ˆë¬´ ì§€ì €ë¶„ í•˜ì—¬ ì œì™¸í•¨\n",
        "  - íŠ¹ì„±ì˜ ì „ì²˜ë¦¬: ì†Œë¬¸ìí™”, ì•ŒíŒŒë²³ê³¼ ìˆ«ì ' , 'ë¹¼ê³  ì‚­ì œ\n",
        "  - ' , 'ê¸°ì¤€ìœ¼ë¡œ êµ¬ë¶„ì§“ê³  ìƒˆë¡œìš´ íŠ¹ì„±ìœ¼ë¡œ ìƒì„± í›„ ê¸°ì¡´ 'Tags'ì‚­ì œ\n",
        "- ë¦¬ë·°ë“¤ì˜ í† í°í™”\n",
        "  - ì†Œë¬¸ìí™” ë° ë¶ˆìš©ì–´ì²˜ë¦¬\n",
        "  - í‘œì œì–´ì¶”ì¶œ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MxGoZeGlUoA"
      },
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "STOP_WORDS_union = nlp.Defaults.stop_words.union(['negative', 't', 'hotel', 'didn', ' '])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_s8I4hTlLBRI"
      },
      "source": [
        " # # êµ­ê°€-ë„ì‹œ ë¶„ë¦¬ - ìŠ¤í˜ì¸ë§Œ í• ë•ŒëŠ” ë¶ˆí•„ìš”í•¨\n",
        "# def split_country_city(data):\n",
        "#   try:\n",
        "#     data['City'] = data['Hotel_Name'].str.split(' ').str[-2]\n",
        "#     data['Country'] = data['Hotel_Address'].str.split(' ').str[-1]\n",
        "#     data = data.drop('Hotel_Address', axis=1)\n",
        "#     data = data[['Country', 'City', 'Hotel_Name', 'Negative_Review', 'Positive_Review', 'Tags']]\n",
        "#     print(\"split_city_country: Done!\")\n",
        "#   except:\n",
        "#     print(\"split_city_country: already Done Or Not found [Hotel_Address]\")\n",
        "#   return data\n",
        "\n",
        "# ê°™ì€ í˜¸í…”ë¦¬ë·° í•©ì³ì„œ í˜¸í…”ë“¤ì˜ ë¦¬ë·° ë¦¬ìŠ¤íŠ¸ë¡œ ë§Œë“¤ê¸°\n",
        "def split_hotel_review(data, review_category):\n",
        "  try:\n",
        "    reviews = []\n",
        "    hotel_list = data['Hotel_Name'].unique()\n",
        "    for i in hotel_list:\n",
        "      review = ''\n",
        "      hotel1 = data[data['Hotel_Name'] == i]\n",
        "      for i in hotel1[review_category]:\n",
        "        review = review +'. '+ i\n",
        "      reviews.append(review)\n",
        "    print(\"split_hotel_review: Done\")\n",
        "  except:\n",
        "    print(\"split_hotel_review: already Done Or Not found [Hotel_Name]\")\n",
        "  return reviews\n",
        "\n",
        "# ['Tags'] ì „ì²˜ë¦¬ìš© \n",
        "def tags_preprocessing(data):\n",
        "  for idx, text in enumerate(data):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"[^a-z0-9,]\", '', text)\n",
        "    text = text.replace('\\n', ' ')\n",
        "    data[idx] = text\n",
        "  print('tags_preprocessing: Done!')\n",
        "  return data\n",
        "\n",
        "# ë¦¬ë·° í† í°í™”\n",
        "def get_lemmas(data):\n",
        "  tokenizer = spacy.tokenizer.Tokenizer(nlp.vocab)\n",
        "  tokens = []\n",
        "  for doc in tokenizer.pipe(data):\n",
        "    lemmas = []\n",
        "    for token in doc: \n",
        "      if token.text.lower() not in STOP_WORDS_union:\n",
        "        if ((token.is_stop == False) and (token.is_punct == False)) and (token.pos_ != 'PRON'):\n",
        "          lemmas.append(token.lemma_.lower())\n",
        "    tokens.append(lemmas)\n",
        "  print(\"get_lemmas: Done!\")\n",
        "  return tokens\n",
        "\n",
        "# íƒœê·¸ ë¶„ë¥˜í•˜ê¸°\n",
        "def split_Tags(data):\n",
        "  count = 0\n",
        "  try:\n",
        "    data['travel_perpos'] = data['Tags'].str.split(',').str[0]\n",
        "    # data['traveler_category'] = data['Tags'].str.split(',').str[1]\n",
        "    # data['room_condition'] = data['Tags'].str.split(',').str[2]\n",
        "    data = data.drop('Tags', axis=1)\n",
        "    print(\"split_Tags: Done, Without Submitted_from_mobiledevice!\")\n",
        "  except:\n",
        "    print(\"split_Tags: already Done Or Not found [Tags]\")\n",
        "  return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTG3KWDvfoDn"
      },
      "source": [
        "# df = split_city_country(df)\n",
        "df['Tags'] = tags_preprocessing(df['Tags'])\n",
        "df = split_Tags(df)\n",
        "\n",
        "Negative_Review = split_hotel_review(df, 'Negative_Review')\n",
        "Positive_Review = split_hotel_review(df, 'Positive_Review')\n",
        "\n",
        "df['Negative_Review'] = get_lemmas(df['Negative_Review'])\n",
        "df['Positive_Review'] = get_lemmas(df['Positive_Review'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9UTGBeMj-z6"
      },
      "source": [
        "from collections import Counter\n",
        "def word_count(docs):\n",
        "    \"\"\" í† í°í™”ëœ ë¬¸ì„œë“¤ì„ ì…ë ¥ë°›ì•„ í† í°ì„ ì¹´ìš´íŠ¸ í•˜ê³  ê´€ë ¨ëœ ì†ì„±ì„ ê°€ì§„ ë°ì´í„°í”„ë ˆì„ì„ ë¦¬í„´í•©ë‹ˆë‹¤.\n",
        "    Args:\n",
        "        docs (series or list): í† í°í™”ëœ ë¬¸ì„œê°€ ë“¤ì–´ìˆëŠ” list\n",
        "    Returns:\n",
        "        list: Dataframe\n",
        "    \"\"\"\n",
        "    # ì „ì²´ ì½”í¼ìŠ¤ì—ì„œ ë‹¨ì–´ ë¹ˆë„ ì¹´ìš´íŠ¸\n",
        "    word_counts = Counter()\n",
        "\n",
        "    # ë‹¨ì–´ê°€ ì¡´ì¬í•˜ëŠ” ë¬¸ì„œì˜ ë¹ˆë„ ì¹´ìš´íŠ¸, ë‹¨ì–´ê°€ í•œ ë²ˆ ì´ìƒ ì¡´ì¬í•˜ë©´ +1\n",
        "    word_in_docs = Counter()\n",
        "\n",
        "    # ì „ì²´ ë¬¸ì„œì˜ ê°¯ìˆ˜\n",
        "    total_docs = len(docs)\n",
        "\n",
        "    for doc in docs:\n",
        "        word_counts.update(doc)\n",
        "        word_in_docs.update(set(doc))\n",
        "\n",
        "    temp = zip(word_counts.keys(), word_counts.values())\n",
        "\n",
        "    wc = pd.DataFrame(temp, columns = ['word', 'count'])\n",
        "\n",
        "    # ë‹¨ì–´ì˜ ìˆœìœ„\n",
        "    # method='first': ê°™ì€ ê°’ì˜ ê²½ìš° ë¨¼ì €ë‚˜ì˜¨ ìš”ì†Œë¥¼ ìš°ì„ \n",
        "    wc['rank'] = wc['count'].rank(method='first', ascending=False)\n",
        "    total = wc['count'].sum()\n",
        "\n",
        "    # ì½”í¼ìŠ¤ ë‚´ ë‹¨ì–´ì˜ ë¹„ìœ¨\n",
        "    wc['percent'] = wc['count'].apply(lambda x: x / total)\n",
        "\n",
        "    wc = wc.sort_values(by='rank')\n",
        "\n",
        "    # ëˆ„ì  ë¹„ìœ¨\n",
        "    # cumsum() : cumulative sum\n",
        "    wc['cul_percent'] = wc['percent'].cumsum()\n",
        "\n",
        "    temp2 = zip(word_in_docs.keys(), word_in_docs.values())\n",
        "    ac = pd.DataFrame(temp2, columns=['word', 'word_in_docs'])\n",
        "    wc = ac.merge(wc, on='word')\n",
        "    \n",
        "    # ì „ì²´ ë¬¸ì„œ ì¤‘ ì¡´ì¬í•˜ëŠ” ë¹„ìœ¨\n",
        "    wc['word_in_docs_percent'] = wc['word_in_docs'].apply(lambda x: x / total_docs)\n",
        "\n",
        "    return wc.sort_values(by='rank')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rkxn3dxzayh"
      },
      "source": [
        "import squarify\n",
        "Negative_Review_wc = word_count(df['Negative_Review'])\n",
        "Negative_Review_wc_top10 = Negative_Review_wc[Negative_Review_wc['rank'] <= 10]\n",
        "print(\"Negative_Review_word_top10\")\n",
        "squarify.plot(sizes=Negative_Review_wc_top10['percent'], label=Negative_Review_wc_top10['word'], alpha=0.6 )\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "Negative_Review_wc_top10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCvMOON9lXQq"
      },
      "source": [
        "Positive_Review_wc = word_count(df['Positive_Review'])\n",
        "Positive_Review_wc_top10 = Positive_Review_wc[Positive_Review_wc['rank'] <= 10]\n",
        "print(\"Positive_Review_word_top10\")\n",
        "squarify.plot(sizes=Positive_Review_wc_top10['percent'], label=Positive_Review_wc_top10['word'], alpha=0.6 )\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "Positive_Review_wc_top10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PL0zSH_utxuQ"
      },
      "source": [
        "### ë¦¬ë·° ë²¡í„°í™”(TF-IDF)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "if9iYATiuXa_"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1Tc0q2M2vnm"
      },
      "source": [
        "# plot ìŠ¤íƒ€ì¼ê³¼ í°íŠ¸ í¬ê¸°ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.\n",
        "sns.set(style='whitegrid', font_scale=1.15)\n",
        "\n",
        "# ë¬¸ì„œë³„ ë‹¨ì–´ì˜ ìˆ˜ ë¶„í¬ë„ ê·¸ë¦¬ëŠ” í•¨ìˆ˜\n",
        "def plot_text_length_dist(text_list):\n",
        "\n",
        "    # ë¬¸ì¥ì´ ìš”ì†Œì¸ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°›ì•„ ê° ë¬¸ì„œì˜ ë‹¨ì–´ ìˆ˜ë¥¼ ê°€ì§„ ë¦¬ìŠ¤íŠ¸ë¥¼ ë§Œë“­ë‹ˆë‹¤\n",
        "    num_words = [len(doc.split()) for doc in text_list]\n",
        "    \n",
        "    sns.displot(num_words)\n",
        "    plt.title('# of words per documents')\n",
        "    plt.xlabel('Number of words')\n",
        "    plt.ylabel('Number of documents')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58PrBKnRiwhy"
      },
      "source": [
        "plot_text_length_dist(Positive_Review)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2U0zWGrA2xJi"
      },
      "source": [
        "plot_text_length_dist(Negative_Review)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09Vjb7KF38H_"
      },
      "source": [
        "# spacy tokenizer í•¨ìˆ˜\n",
        "def tokenize(document):\n",
        "    \n",
        "    doc = nlp(document)\n",
        "    # punctuations: !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
        "    return [token.lemma_.strip() for token in doc if (token.is_stop != True) and (token.is_punct != True) and (token.is_alpha == True)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvWQPtqGlzDc"
      },
      "source": [
        "# Tf-IDF\n",
        "N_tfidf = TfidfVectorizer(stop_words='english'\n",
        "                        ,tokenizer=tokenize\n",
        "                        ,ngram_range=(1,2)\n",
        "                        ,max_df=.7\n",
        "                        ,min_df=3\n",
        "                        ,max_features = 20000\n",
        "                       )\n",
        "P_tfidf = TfidfVectorizer(stop_words='english'\n",
        "                        ,tokenizer=tokenize\n",
        "                        ,ngram_range=(1,2)\n",
        "                        ,max_df=.7\n",
        "                        ,min_df=3\n",
        "                        ,max_features = 20000\n",
        "                       )\n",
        "Negative_Review_dtm = N_tfidf.fit_transform(Negative_Review)\n",
        "Negative_Review_dtm = pd.DataFrame(Negative_Review_dtm.todense(), columns=N_tfidf.get_feature_names())\n",
        "print(Negative_Review_dtm.head())\n",
        "\n",
        "Positive_Review_dtm = P_tfidf.fit_transform(Positive_Review)\n",
        "Positive_Review_dtm = pd.DataFrame(Positive_Review_dtm.todense(), columns=P_tfidf.get_feature_names())\n",
        "print(Positive_Review_dtm.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPHBbsf2kHNa"
      },
      "source": [
        "### ìœ ì‚¬ë„ë¥¼ ì´ìš©í•œ ë¬¸ì„œê²€ìƒ‰(NearestNeighbor (K-NN, K-ìµœê·¼ì ‘ ì´ì›ƒ))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOBsEfsH3-In"
      },
      "source": [
        "# NearestNeighbor (K-NN, K-ìµœê·¼ì ‘ ì´ì›ƒ)\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# dtmì„ ì‚¬ìš©íˆ NN ëª¨ë¸ì„ í•™ìŠµì‹œí‚µë‹ˆë‹¤. (ë””í´íŠ¸)ìµœê·¼ì ‘ 5 ì´ì›ƒ.\n",
        "Negative_Review_nn = NearestNeighbors(n_neighbors=5, algorithm='kd_tree')\n",
        "Negative_Review_nn.fit(Negative_Review_dtm)\n",
        "\n",
        "Positive_Review_nn = NearestNeighbors(n_neighbors=5, algorithm='kd_tree')\n",
        "Positive_Review_nn.fit(Positive_Review_dtm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTGsJh0N4hdK"
      },
      "source": [
        "Negative_Review_nn.kneighbors([Negative_Review_dtm.iloc[0].values])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBbGGb__joKG"
      },
      "source": [
        "Positive_Review_nn.kneighbors([Positive_Review_dtm.iloc[0].values])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmS62jV_BZRy"
      },
      "source": [
        "ê¸°ëŠ¥ì¶”ê°€"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GIa8qHy_2UZ"
      },
      "source": [
        "# ['travel_perpos']ì„ í†µí•´ì„œ í•´ë‹¹ ìœ í˜•ì—ì„œ ê°€ì¥ ë§ì´ ì˜ˆì•½ëœ ìƒìœ„ 5ê°œì˜ í˜¸í…” ì•Œë ¤ì£¼ê¸°\n",
        "def top5_hotel_by_travel_perpos(data, travel_perpos):\n",
        "  travel_perpos_ls = data['travel_perpos'].unique()\n",
        "  hotel_list = data['Hotel_Name'].unique()\n",
        "  dic = {}\n",
        "  for i in hotel_list:\n",
        "    s = data[data['Hotel_Name']==i]['travel_perpos']=='travel_perpos'\n",
        "    dic[i]=s.count()\n",
        "  top5 = sorted(dic.items(), key=lambda x: x[1], reverse=True)[0:5]\n",
        "  print(f\"ì…ë ¥ëœ ìˆ™ë°•ëª©ì ì€ '{travel_perpos}'ì´ë©°, í•´ë‹¹ ëª©ì ìœ¼ë¡œ ê°€ì¥ë§ì´ ì´ìš©ëœ ìƒìœ„5ê°œ í˜¸í…”ê³¼ ì´ìš©ì ìˆ˜ ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤. \")\n",
        "  return top5\n",
        "\n",
        "# ì‚¬ìš©ìì˜ ì¶”ê°€ì ì¸ ì¡°ê±´ì— ë”°ë¼ í˜¸í…” ì¶”ì²œí•˜ê¸°\n",
        "def kneighbors(data, Negative, Positive):\n",
        "  hotel_list = data['Hotel_Name'].unique()\n",
        "  test_N = N_tfidf.transform(Negative)\n",
        "  test_P = P_tfidf.transform(Positive)\n",
        "  Negative_kneighbors=Negative_Review_nn.kneighbors(test_N.todense())[1][0]\n",
        "  Positive_kneighbors=Positive_Review_nn.kneighbors(test_P.todense())[1][0]\n",
        "  print(f\"ì…ë ¥ëœ ì‹«ì–´í•˜ëŠ” í˜¸í…”ì¡°ê±´ì€\\n {Negative}\\nì´ë©°, ì…ë ¥ëœ ì¡°ê±´ê³¼ ë¹„ìŠ·í•œ ë¦¬ë·°ê°€ ìˆëŠ” í˜¸í…”ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\")\n",
        "  for i in hotel_list[Negative_kneighbors]:\n",
        "    print(i)\n",
        "  print(\"\\n\")\n",
        "  print(f\"ì…ë ¥ëœ ì„ í˜¸í•˜ëŠ” í˜¸í…”ì¡°ê±´ì€\\n {Positive}\\nì´ë©°, ì…ë ¥ëœ ì¡°ê±´ê³¼ ë¹„ìŠ·í•œ ë¦¬ë·°ê°€ ìˆëŠ” í˜¸í…”ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\")\n",
        "  for i in hotel_list[Positive_kneighbors]:\n",
        "    print(i)\n",
        "  return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjItE40PlFGt"
      },
      "source": [
        "## ê²°ê³¼ ì•Œë ¤ì£¼ê¸°\n",
        "- ['travel_perpos']ì„ í†µí•´ì„œ í•´ë‹¹ ìœ í˜•ì—ì„œ ìˆ™ë°•ë¦¬ë·°ê°€ ê°€ì¥ ë§ì€ í˜¸í…” ì•Œë ¤ì£¼ê¸°\n",
        "- ì‹«ì–´í•˜ëŠ” í˜¸í…”ì¡°ê±´ì„ í†µí•´ ë¹„ìŠ·í•œ ë„¤ê±°í‹°ë¸Œë¦¬ë·°ê°€ ìˆëŠ” í˜¸í…” ì•Œë ¤ì£¼\n",
        "- ì¢‹ì•„í•˜ëŠ” í˜¸í…”ì¡°ê±´ì„ í†µí•´ ë¹„ìŠ·í•œ í¬ì§€í‹°ë¸Œë¦¬ë·°ê°€ ìˆëŠ” í˜¸í…” ì•Œë ¤ì£¼ê¸°"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_WkDznxpWtg"
      },
      "source": [
        "# ['travel_perpos']ì˜ ì¢…ë¥˜\n",
        "travel_perpos = ['leisuretrip', 'businesstrip', 'couple', 'solotraveler',\n",
        "       'familywithyoungchildren', 'withapet', 'group',\n",
        "       'travelerswithfriends', 'familywitholderchildren']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tr8gFKr9E4wt"
      },
      "source": [
        "# bug, nosie, unkind staff\n",
        "# nice step, good breakfast, pool"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmvhHs17DV7K"
      },
      "source": [
        "user1 = {\n",
        "    'travel_perpos':input(\"travel_perpos?:\"),\n",
        "    'n1':[input(\"negative_r?: \")],\n",
        "    'p1':[input(\"positive_r?: \")]\n",
        "    }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1ql-mEpAx-w"
      },
      "source": [
        "top5_hotel_by_travel_perpos(df, user1['travel_perpos'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Suy7HQBRFi71"
      },
      "source": [
        "kneighbors(df, user1['n1'], user1['p1'])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}